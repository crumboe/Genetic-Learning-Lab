{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5583c11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5583c11",
        "outputId": "8ae39440-fa81-4604-9d95-19557a567f56"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# Run this cell first if you haven't already installed these packages\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package using pip\"\"\"\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# List of required packages\n",
        "required_packages = [\n",
        "    'gymnasium',           # Reinforcement learning environments (CartPole)\n",
        "    'numpy',              # Numerical computing\n",
        "    'matplotlib',         # Plotting and visualization\n",
        "    'pygame',              # For rendering the environment\n",
        "]\n",
        "\n",
        "print(\"Checking and installing required packages...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        __import__(package.split('[')[0])  # Handle packages with extras like 'package[extra]'\n",
        "        print(f\"✓ {package} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package}...\")\n",
        "        install_package(package)\n",
        "        print(f\"✓ {package} installed successfully\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"All required packages are installed!\")\n",
        "print(\"\\nYou can now run the rest of the notebook.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9ae1d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9ae1d7",
        "outputId": "3c67d1d1-46b9-4326-cefd-df4baf0b5091"
      },
      "outputs": [],
      "source": [
        "# Configure matplotlib for Google Colab (prevents flashing)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.ion()  # Turn on interactive mode\n",
        "\n",
        "print(\"✓ Matplotlib configured for smooth updates in Google Colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e0d566c",
      "metadata": {
        "id": "7e0d566c"
      },
      "source": [
        "# CartPole PID Control with Genetic Algorithm\n",
        "\n",
        "## What You're Actually Doing Here\n",
        "\n",
        "Look, you've got a cart with a pole on it. The pole wants to fall over. Your job is to tune a PID controller so it doesn't. Simple, right? Wrong. Tuning PID controllers manually is a pain in the ass - you tweak one parameter, something improves, then two other things break.\n",
        "\n",
        "So instead of spending hours doing that, we're letting evolution do the work. That's what genetic algorithms are good for: searching through parameter spaces that would take you forever to explore by hand.\n",
        "\n",
        "**What you should get out of this:**\n",
        "- See how genetic algorithms actually work (not just read about them)\n",
        "- Understand what the hell Kp, Ki, and Kd actually do to a control system\n",
        "- Watch evolution happen in real time (it's cooler than it sounds)\n",
        "- Break things by changing parameters and see what happens\n",
        "\n",
        "---\n",
        "\n",
        "## The Problem\n",
        "\n",
        "You've got a cart on a track. There's a pole attached to the cart with a hinge. The pole starts slightly tilted. Physics wants to make it fall. You need to push the cart left or right to keep the pole balanced.\n",
        "\n",
        "This is called an inverted pendulum problem. Engineers love this one because it's simple enough to understand but hard enough to be interesting.\n",
        "\n",
        "**How we're solving it:**\n",
        "- Measure the pole angle (that's your error signal)\n",
        "- Feed it to a PID controller (we'll explain this later)\n",
        "- Controller outputs a force value\n",
        "- Apply that force to the cart\n",
        "- Repeat every 0.02 seconds\n",
        "\n",
        "---\n",
        "\n",
        "## Parameters You Can Mess With\n",
        "\n",
        "### Environment Stuff\n",
        "| Parameter | What it does | Default |\n",
        "|-----------|-------------|---------|\n",
        "| `FAILURE_ANGLE_DEGREES` | How far the pole can tilt before you lose | 90° |\n",
        "| `FORCE_MAGNITUDE` | Max force you can push with | 10.0 N |\n",
        "| `REWARD_TYPE` | What counts as \"good\" performance | \"comprehensive\" |\n",
        "\n",
        "The default CartPole only lets the pole tilt 12 degrees. That's boring and too easy. We set it to 90 degrees by default. Much more interesting.\n",
        "\n",
        "**Reward types** (this is important):\n",
        "- `\"default\"`: Get 1 point per timestep you survive. That's it.\n",
        "- `\"angle_based\"`: Get more points when the pole is closer to vertical\n",
        "- `\"comprehensive\"`: Balance multiple things - angle, velocity, position\n",
        "- `\"negative_angle\"`: Punishment-based (usually works worse, but try it)\n",
        "- `\"custom\"`: Write your own (see challenge section)\n",
        "\n",
        "### Genetic Algorithm Settings\n",
        "| Parameter | What it does | Default | Notes |\n",
        "|-----------|-------------|---------|-------|\n",
        "| `POPULATION_SIZE` | How many PID controllers per generation | 20 | More = slower but explores better |\n",
        "| `GENERATIONS` | How many rounds of evolution | 30 | Usually converges before this |\n",
        "| `EPISODES_PER_EVAL` | Test runs to average | 3 | Reduces random luck |\n",
        "| `MUTATION_RATE` | How often parameters randomly change | 0.3 | Lower = more stable |\n",
        "| `MUTATION_EFFECT` | How BIG those changes are | 0.15 | Lower = fine tuning |\n",
        "| `CROSSOVER_RATE` | How often parents mix genes | 0.8 | Usually keep this high |\n",
        "| `ELITISM` | Always keep the best solution | True | Turn this off at your own risk |\n",
        "\n",
        "### PID Search Ranges\n",
        "These tell the algorithm where to look for good parameters:\n",
        "\n",
        "| Parameter | Range | What it controls |\n",
        "|-----------|-------|---------|\n",
        "| `KP_RANGE` | (-50, 50) | Proportional: react to current error |\n",
        "| `KI_RANGE` | (-20, 20) | Integral: fix accumulated drift |\n",
        "| `KD_RANGE` | (-30, 30) | Derivative: dampen oscillations |\n",
        "\n",
        "Notice the ranges include negative values. Yeah, that's intentional. Sometimes you need negative gains to make the controller stable. Don't ask me why, just try it and see.\n",
        "\n",
        "---\n",
        "\n",
        "## How the Genetic Algorithm Works\n",
        "\n",
        "Okay, here's the process. It's not complicated, just repetitive:\n",
        "\n",
        "```\n",
        "START:\n",
        "  Make a random population of PID controllers\n",
        "  \n",
        "LOOP (for each generation):\n",
        "  1. Test every controller on the CartPole\n",
        "  2. Give each one a fitness score (higher = better)\n",
        "  3. Pick the good ones (tournament selection)\n",
        "  4. Make them \"reproduce\" (crossover their parameters)\n",
        "  5. Randomly mutate some parameters (exploration)\n",
        "  6. Keep the best one no matter what (elitism)\n",
        "  7. This is your new population\n",
        "  \n",
        "  If we've done enough generations, STOP\n",
        "  Otherwise, go back to step 1\n",
        "  \n",
        "RESULT: Best PID parameters found\n",
        "```\n",
        "\n",
        "That's it. Evolution is just trial and error with a clever selection strategy.\n",
        "\n",
        "---\n",
        "\n",
        "## What's a PID Controller Anyway?\n",
        "\n",
        "If you've never seen this before: PID stands for Proportional-Integral-Derivative. It's a control algorithm that's been around since the 1920s. It's used in EVERYTHING - cruise control, temperature control, drones, industrial robots, you name it.\n",
        "\n",
        "The math is simple:\n",
        "\n",
        "**force = Kp × error + Ki × ∫(error)dt + Kd × d(error)/dt**\n",
        "\n",
        "Breaking that down:\n",
        "- **Kp (Proportional):** Push harder when the pole is tilted more. Simple.\n",
        "- **Ki (Integral):** If there's a constant drift, this fixes it over time. Prevents steady-state error.\n",
        "- **Kd (Derivative):** If the pole is falling fast, this adds damping. Prevents overshooting.\n",
        "\n",
        "The problem? Picking good values for Kp, Ki, and Kd. That's where the genetic algorithm comes in.\n",
        "\n",
        "---\n",
        "\n",
        "## Things to Try\n",
        "\n",
        "1. **Make it easier:** Set `FAILURE_ANGLE_DEGREES = 12` (original CartPole difficulty)\n",
        "2. **Make it harder:** Keep it at 90 degrees and reduce `FORCE_MAGNITUDE = 5.0`\n",
        "3. **Speed things up:** Crank `POPULATION_SIZE = 50` and `MUTATION_RATE = 0.5` (less stable but faster)\n",
        "4. **Fine-tune existing solution:** Lower `MUTATION_EFFECT = 0.05` (smaller changes)\n",
        "5. **Try different rewards:** Change `REWARD_TYPE` and see how it affects the final controller behavior\n",
        "\n",
        "Don't just run it once and call it done. Change stuff. Break it. See what happens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221e7311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "221e7311",
        "outputId": "b77592bf-bc1e-45ec-fc01-1d5709f9f48c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# HYPERPARAMETERS & CONFIGURATION\n",
        "# ============================================================================\n",
        "# Adjust these values to control the learning algorithm and environment\n",
        "\n",
        "# --- Environment Configuration ---\n",
        "FAILURE_ANGLE_DEGREES = 90  # Pole angle limit before failure (default: 12°, larger = harder)\n",
        "FORCE_MAGNITUDE = 10.0      # Maximum force that can be applied to cart (default CartPole: 10.0)\n",
        "REWARD_TYPE = \"custom_15_deg\"  # Reward function: \"default\", \"angle_based\", \"comprehensive\", \"negative_angle\"\n",
        "\n",
        "# --- PID Controller Configuration ---\n",
        "INTEGRAL_LIMIT = 10.0       # Maximum absolute value for integral term (prevents windup)\n",
        "PID_TIMESTEP = 0.02         # Time step for PID calculations (matches environment tau=0.02)\n",
        "\n",
        "# --- Genetic Algorithm - Population & Evolution ---\n",
        "POPULATION_SIZE =  20       # Number of individuals per generation (larger = more exploration, slower)\n",
        "GENERATIONS = 60            # Number of evolution cycles (more = longer search, better convergence)\n",
        "EPISODES_PER_EVAL = 3       # Number of test runs to average for fitness (more = robust but slower)\n",
        "MAX_STEPS_PER_EPISODE = 500  # Maximum steps in each episode before truncation\n",
        "\n",
        "# --- Genetic Algorithm - Parameter Search Ranges ---\n",
        "# These define the search space for PID gains. Negative values allow corrective action.\n",
        "KP_RANGE = (-50, 50)        # Proportional gain range: responds to current error\n",
        "KI_RANGE = (-20, 20)        # Integral gain range: responds to accumulated error over time\n",
        "KD_RANGE = (-30, 30)        # Derivative gain range: responds to rate of change of error\n",
        "\n",
        "# --- Genetic Algorithm - Evolution Parameters ---\n",
        "MUTATION_RATE = 0.3         # Probability of mutating each gene (0.0-1.0, lower = more stable)\n",
        "MUTATION_EFFECT = 0.15      # Size of mutations as fraction of current value (lower = finer tuning)\n",
        "CROSSOVER_RATE = 0.8        # Probability of crossover between parents (0.0-1.0)\n",
        "ELITISM = True              # Keep best individual in next generation (recommended: True)\n",
        "\n",
        "VISUALIZE_ALL_INDIVIDUALS_DURING_TRAINING = False\n",
        "\n",
        "RENDER_EVERY_N_STEPS = 20         # Update visualization every N steps (lower = smoother but slower)\n",
        "\n",
        "# ============================================================================\n",
        "print(\"=\"*70)\n",
        "print(\"CONFIGURATION LOADED\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Environment:\")\n",
        "print(f\"  Failure angle: {FAILURE_ANGLE_DEGREES}°\")\n",
        "print(f\"  Force magnitude: {FORCE_MAGNITUDE}\")\n",
        "print(f\"  Reward type: {REWARD_TYPE}\")\n",
        "print(f\"\\nPID Controller:\")\n",
        "print(f\"  Integral limit: {INTEGRAL_LIMIT}\")\n",
        "print(f\"  Timestep: {PID_TIMESTEP}\")\n",
        "print(f\"\\nGenetic Algorithm:\")\n",
        "print(f\"  Population: {POPULATION_SIZE} individuals\")\n",
        "print(f\"  Generations: {GENERATIONS}\")\n",
        "print(f\"  Episodes per evaluation: {EPISODES_PER_EVAL}\")\n",
        "print(f\"  Search ranges: Kp{KP_RANGE}, Ki{KI_RANGE}, Kd{KD_RANGE}\")\n",
        "print(f\"  Mutation rate: {MUTATION_RATE}, effect: {MUTATION_EFFECT}\")\n",
        "print(f\"  Crossover rate: {CROSSOVER_RATE}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a666344f",
      "metadata": {
        "id": "a666344f"
      },
      "source": [
        "\n",
        "### Why We Need These Wrapper Classes\n",
        "\n",
        "Look, the default CartPole environment is set up for reinforcement learning research, not for testing PID controllers. So we need to modify it. That's what these wrappers do.\n",
        "\n",
        "**Three wrappers, three problems they solve:**\n",
        "\n",
        "**1. LargeAngleCartPole**\n",
        "- Problem: Default failure angle is only ±12 degrees\n",
        "- Why that sucks: The pole barely has to tilt before the episode ends. Too easy.\n",
        "- Fix: Override the threshold to ±90 degrees (or whatever you want)\n",
        "- Result: Now you actually have to balance the thing\n",
        "\n",
        "**2. ContinuousForceCartPole**\n",
        "- Problem: Original action space is discrete - either push left or push right, that's it\n",
        "- Why that sucks: PID controllers output continuous values. We need to apply variable forces.\n",
        "- Fix: Change the action space to continuous (-10 to +10 Newtons)\n",
        "- Implementation detail: We have to manually apply the physics because we're bypassing the original step function\n",
        "- Result: PID output becomes the exact force applied to the cart\n",
        "\n",
        "**3. CustomRewardCartPole**\n",
        "- Problem: Default reward is just +1 for every timestep you don't fail\n",
        "- Why that sucks: Doesn't distinguish between \"barely surviving\" and \"perfectly balanced\"\n",
        "- Fix: Multiple reward functions that actually measure quality of control\n",
        "- Options: angle-based, comprehensive (multi-factor), negative penalties, or custom\n",
        "- Result: The GA can optimize for different objectives depending on what you care about\n",
        "\n",
        "**The chain:**\n",
        "Base CartPole → LargeAngleCartPole → ContinuousForceCartPole → CustomRewardCartPole\n",
        "\n",
        "Each wrapper modifies one aspect. Could we do this in one big wrapper? Sure. But then if something breaks you'd have no idea which part is the problem. Separation of concerns, people.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284562f1",
      "metadata": {
        "id": "284562f1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# Create a wrapper to increase the failure angle\n",
        "class LargeAngleCartPole(gym.Wrapper):\n",
        "    def __init__(self, env, theta_threshold_radians=np.deg2rad(90)):\n",
        "        super().__init__(env)\n",
        "        # Override the theta threshold (default is ~0.2095 radians or ~12 degrees)\n",
        "        self.env.unwrapped.theta_threshold_radians = theta_threshold_radians\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)\n",
        "\n",
        "    def step(self, action):\n",
        "        return self.env.step(action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c230032",
      "metadata": {
        "id": "8c230032"
      },
      "outputs": [],
      "source": [
        "# Create a wrapper to convert discrete actions to continuous force\n",
        "class ContinuousForceCartPole(gym.Wrapper):\n",
        "    def __init__(self, env, force_mag=100.0):\n",
        "        \"\"\"\n",
        "        Converts the discrete CartPole action space to continuous force control.\n",
        "\n",
        "        Args:\n",
        "            force_mag: Maximum force magnitude that can be applied (default CartPole uses 10.0)\n",
        "        \"\"\"\n",
        "        super().__init__(env)\n",
        "        self.force_mag = force_mag\n",
        "        # Change action space from Discrete(2) to continuous Box\n",
        "        self.action_space = gym.spaces.Box(low=-force_mag, high=force_mag, shape=(1,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)\n",
        "\n",
        "    def step(self, action):\n",
        "        # action is now a continuous value between -force_mag and +force_mag\n",
        "        # Map it to the CartPole's internal force application\n",
        "        # Positive = push right, Negative = push left\n",
        "\n",
        "        if isinstance(action, np.ndarray):\n",
        "            force = np.clip(action[0], -self.force_mag, self.force_mag)\n",
        "        else:\n",
        "            force = np.clip(action, -self.force_mag, self.force_mag)\n",
        "\n",
        "        # Access the underlying CartPole environment\n",
        "        unwrapped_env = self.env.unwrapped\n",
        "\n",
        "        # Manually apply physics (copied from CartPole source)\n",
        "        x, x_dot, theta, theta_dot = unwrapped_env.state\n",
        "\n",
        "        costheta = np.cos(theta)\n",
        "        sintheta = np.sin(theta)\n",
        "\n",
        "        # Physics constants from CartPole\n",
        "        gravity = unwrapped_env.gravity\n",
        "        masscart = unwrapped_env.masscart\n",
        "        masspole = unwrapped_env.masspole\n",
        "        total_mass = masspole + masscart\n",
        "        length = unwrapped_env.length\n",
        "        polemass_length = masspole * length\n",
        "        tau = unwrapped_env.tau\n",
        "\n",
        "        # Apply continuous force\n",
        "        temp = (force + polemass_length * theta_dot**2 * sintheta) / total_mass\n",
        "        thetaacc = (gravity * sintheta - costheta * temp) / (\n",
        "            length * (4.0 / 3.0 - masspole * costheta**2 / total_mass)\n",
        "        )\n",
        "        xacc = temp - polemass_length * thetaacc * costheta / total_mass\n",
        "\n",
        "        # Euler integration\n",
        "        x = x + tau * x_dot\n",
        "        x_dot = x_dot + tau * xacc\n",
        "        theta = theta + tau * theta_dot\n",
        "        theta_dot = theta_dot + tau * thetaacc\n",
        "\n",
        "        unwrapped_env.state = (x, x_dot, theta, theta_dot)\n",
        "\n",
        "        # Check termination conditions\n",
        "        terminated = bool(\n",
        "            x < -unwrapped_env.x_threshold\n",
        "            or x > unwrapped_env.x_threshold\n",
        "            or theta < -unwrapped_env.theta_threshold_radians\n",
        "            or theta > unwrapped_env.theta_threshold_radians\n",
        "        )\n",
        "\n",
        "        reward = 1.0 if not terminated else 0.0\n",
        "\n",
        "        return np.array(unwrapped_env.state, dtype=np.float32), reward, terminated, False, {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466cbb1e",
      "metadata": {
        "id": "466cbb1e"
      },
      "source": [
        "## Custom Reward Functions (aka The Challenges)\n",
        "\n",
        "Alright, here's where you actually get to design something instead of just running my code. The reward function tells the GA what \"good\" means. Design it poorly and evolution will optimize for something stupid. Design it well and you'll get interesting behavior.\n",
        "\n",
        "---\n",
        "\n",
        "### Basic Rules (ignore these at your own peril)\n",
        "\n",
        "**Rule 1: Reward what you want to see happen**\n",
        "- Good: `reward = 1.0 - abs(theta)` (closer to vertical = better)\n",
        "- Bad: Huge negative penalties everywhere (makes everything look equally terrible)\n",
        "\n",
        "**Rule 2: Keep your rewards in a reasonable range**\n",
        "- Don't let one component completely dominate the others\n",
        "- If angle gives rewards of 0-1 but velocity gives penalties of -1000, guess which one the GA will ignore?\n",
        "- Normalize stuff: `angle_component = 1.0 - (abs(theta) / np.deg2rad(90))`\n",
        "\n",
        "**Rule 3: Multiple objectives need balancing**\n",
        "- Want it upright AND still AND centered? Use weights: `reward = w1*angle + w2*velocity + w3*position`\n",
        "- Start with equal weights, see what happens, adjust\n",
        "- This is more art than science\n",
        "\n",
        "**Rule 4: Your reward function will backfire in ways you didn't expect**\n",
        "- Example: Reward only survival time → cart oscillates wildly but never quite fails\n",
        "- Example: Penalize velocity too much → cart doesn't move, pole falls over\n",
        "- Test it. Watch what actually happens.\n",
        "\n",
        "**Rule 5: Start simple, add complexity slowly**\n",
        "- One objective first\n",
        "- Get that working\n",
        "- Then add another\n",
        "- Repeat\n",
        "\n",
        "---\n",
        "\n",
        "### What You Can Actually Use\n",
        "\n",
        "In the step() function you've got these state variables:\n",
        "```python\n",
        "x          # Cart position (roughly -4.8 to 4.8)\n",
        "x_dot      # Cart velocity (how fast it's moving)\n",
        "theta      # Pole angle in radians (0 = straight up)\n",
        "theta_dot  # Angular velocity (how fast it's falling/rising)\n",
        "```\n",
        "\n",
        "You also have these limits:\n",
        "```python\n",
        "self.env.unwrapped.x_threshold           # Cart position limit\n",
        "self.env.unwrapped.theta_threshold_radians  # Angle limit\n",
        "```\n",
        "\n",
        "Use them. They're there for a reason.\n",
        "\n",
        "---\n",
        "\n",
        "### Challenge 1: Make it Stop Moving\n",
        "\n",
        "**Goal:** Cart stays still, pole stays vertical. Like a statue. No movement.\n",
        "\n",
        "**What you need to do:**\n",
        "- Reward keeping the pole upright (obviously)\n",
        "- Penalize ANY velocity - cart moving, pole moving, all of it\n",
        "- Keep the cart near the center\n",
        "\n",
        "**Questions to answer:**\n",
        "- How much should velocity penalties matter compared to angle? Try stuff.\n",
        "- Should you penalize velocity linearly or use squared terms? (Squared = punish fast movement way more)\n",
        "- Bonus points for being perfectly still?\n",
        "\n",
        "**Starting template:**\n",
        "```python\n",
        "# Upright is good\n",
        "angle_reward = 1.0 - (abs(theta) / np.deg2rad(90))\n",
        "\n",
        "# Movement is bad (you fill in the ???)\n",
        "velocity_penalty = -??? * abs(x_dot)\n",
        "angular_velocity_penalty = -??? * abs(theta_dot)\n",
        "position_penalty = -??? * abs(x)\n",
        "\n",
        "custom_reward = angle_reward + velocity_penalty + angular_velocity_penalty + position_penalty\n",
        "```\n",
        "\n",
        "**Hints:**\n",
        "- Start with small penalty values (0.01 to 0.1) and increase if needed\n",
        "- Try squared penalties: `-0.1 * theta_dot**2` penalizes fast movement harder\n",
        "- Maybe add a bonus when everything is nearly zero?\n",
        "- The comprehensive reward function in the code is similar to this - look at it for inspiration (or just modify it)\n",
        "\n",
        "---\n",
        "\n",
        "### Challenge 2: Controlled Oscillation\n",
        "\n",
        "**Goal:** Make the pole sway back and forth smoothly. Like a metronome. Controlled chaos.\n",
        "\n",
        "This is harder than it sounds. You're NOT trying to keep it still. You want rhythmic movement.\n",
        "\n",
        "**Strategy:**\n",
        "- Pole should stay mostly upright but be allowed to tilt\n",
        "- Reward when angular velocity is in a \"good\" range (not zero, not crazy)\n",
        "- Cart shouldn't drift off to one side\n",
        "- Oscillation shouldn't grow out of control\n",
        "\n",
        "**Questions:**\n",
        "- What's a good target angular velocity? 0.1 rad/s? 0.3? Experiment.\n",
        "- How do you reward being \"close to\" a target velocity instead of exactly at it?\n",
        "- How do you prevent the cart from slowly drifting away?\n",
        "- What stops the oscillation from getting bigger and bigger until it fails?\n",
        "\n",
        "**Template:**\n",
        "```python\n",
        "# Allow some tilt (more lenient than Challenge 1)\n",
        "angle_reward = 1.0 - (abs(theta) / np.deg2rad(30))  \n",
        "\n",
        "# Want movement in a specific range\n",
        "target_angular_velocity = 0.2  # Change this!\n",
        "velocity_diff = abs(abs(theta_dot) - target_angular_velocity)\n",
        "oscillation_reward = 1.0 - min(velocity_diff, 1.0)\n",
        "\n",
        "# Don't drift away\n",
        "position_penalty = -??? * abs(x)\n",
        "\n",
        "# Don't spin out of control\n",
        "if abs(theta_dot) > ???:  # Too fast?\n",
        "    stability_penalty = -???\n",
        "else:\n",
        "    stability_penalty = 0\n",
        "\n",
        "custom_reward = angle_reward + oscillation_reward + position_penalty + stability_penalty\n",
        "```\n",
        "\n",
        "**Hints:**\n",
        "- Might be better to reward being within a velocity RANGE rather than hitting one exact value\n",
        "- `np.exp(-velocity_diff**2)` gives you a smooth reward curve (look it up if you don't know what this does)\n",
        "- When theta and theta_dot have opposite signs, that's natural damping - maybe reward that?\n",
        "- Be careful: if you reward velocity too much, the thing will just spin forever\n",
        "\n",
        "---\n",
        "### Challenge 3: The Leaning Tower of CartPole\n",
        "\n",
        "**Goal:** Keep the pole at a 15-degree angle. Not vertical. Tilted. And hold it there.\n",
        "\n",
        "This is surprisingly hard. The system \"wants\" to be vertical or fall over. You're asking it to maintain an unstable equilibrium.\n",
        "\n",
        "**Strategy:**\n",
        "- Reward being close to 15 degrees (or -15 degrees, pick one or allow both)\n",
        "- Penalize deviation from that target angle\n",
        "- Keep velocities low (it should hold the angle, not swing through it)\n",
        "- Cart will need to move to maintain the angle - allow that but keep it centered overall\n",
        "\n",
        "**Questions:**\n",
        "- Should you allow +15 or -15 or both? (Both is harder but more interesting)\n",
        "- How precise do you need to be? Within 2 degrees? 5 degrees?\n",
        "- The cart MUST move to hold an off-vertical angle - how much movement is acceptable?\n",
        "- Should you reward the cart being on the \"correct\" side to balance that angle?\n",
        "\n",
        "**Template:**\n",
        "```python\n",
        "# Target angle (convert to radians)\n",
        "target_angle = np.deg2rad(15)  # or -15, or allow both\n",
        "\n",
        "# Reward being close to target angle\n",
        "angle_diff = abs(abs(theta) - target_angle)\n",
        "angle_reward = 1.0 - min(angle_diff / np.deg2rad(20), 1.0)\n",
        "\n",
        "# Penalize angular velocity (should be holding steady)\n",
        "angular_stability = 1.0 - min(abs(theta_dot), 1.0)\n",
        "\n",
        "# Cart velocity should be small but non-zero\n",
        "cart_velocity_penalty = -??? * (x_dot**2)\n",
        "\n",
        "# Don't let cart drift too far\n",
        "position_penalty = -??? * (x**2)\n",
        "\n",
        "custom_reward = angle_reward + angular_stability + cart_velocity_penalty + position_penalty\n",
        "```\n",
        "\n",
        "**Hints:**\n",
        "- The cart position and angle are coupled - to hold 15° the cart must be offset from center\n",
        "- Maybe reward consistency: if theta was close to target last step AND this step, bonus?\n",
        "- Consider using `np.sign(theta)` to check which direction it's leaning\n",
        "- Physics fact: holding a non-vertical angle requires constant small corrections\n",
        "- The comprehensive reward has angle tolerance logic - adapt that idea\n",
        "- Try `angle_reward = np.exp(-10 * angle_diff**2)` for a sharp peak at the target\n",
        "\n",
        "**Extra challenges:**\n",
        "- Can you make it alternate between +15° and -15°?\n",
        "- Can you make it ramp from vertical to 15° smoothly?\n",
        "- Can you make it hold 15° while slowly moving left to right?\n",
        "\n",
        "---\n",
        "### How to Actually Test Your Reward\n",
        "\n",
        "**Steps:**\n",
        "1. Set `REWARD_TYPE = \"custom\"` in the hyperparameters cell (Cell 2)\n",
        "2. Edit the `\"custom\"` case in the CustomRewardCartPole wrapper (Cell 6)\n",
        "3. Run Cell 2 (config), Cell 7 (environment), Cell 8 (PID classes), Cell 9 (GA class), Cell 10 (training)\n",
        "4. Watch what happens\n",
        "\n",
        "**Debugging tips:**\n",
        "- Print reward components during evaluation to see what's actually happening\n",
        "- Start with ONE objective, make sure it works, THEN add more\n",
        "- Compare fitness values between different reward functions\n",
        "- Most importantly: WATCH the visualization. Does the behavior match what you wanted?\n",
        "\n",
        "**Common mistakes I see every semester:**\n",
        "- Rewards always zero or always the same value → no gradient for learning\n",
        "- One component is 1000x bigger than others → GA ignores the small ones\n",
        "- Conflicting objectives (reward speed AND stillness) → confused evolution, mediocre results\n",
        "- Penalties go to negative infinity → fitness breaks, evolution fails\n",
        "\n",
        "---\n",
        "\n",
        "### What Success Looks Like\n",
        "\n",
        "**For the Still System:**\n",
        "- High fitness (close to theoretical max)\n",
        "- Pole deviation under 2 degrees\n",
        "- Cart velocity near zero\n",
        "- Looks \"locked in place\"\n",
        "\n",
        "**For the Oscillating System:**\n",
        "- Pole sways left-right predictably\n",
        "- Angular velocity is consistent\n",
        "- Cart stays roughly centered\n",
        "- Looks \"controlled\" not \"about to fail\"\n",
        "\n",
        "Now go break things and see what happens. That's how you learn this stuff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a7f230e",
      "metadata": {
        "id": "5a7f230e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a wrapper to customize the reward function\n",
        "class CustomRewardCartPole(gym.Wrapper):\n",
        "    def __init__(self, env, reward_type=\"angle_based\"):\n",
        "        \"\"\"\n",
        "        reward_type options:\n",
        "        - \"default\": Standard +1 per step\n",
        "        - \"angle_based\": Reward based on how upright the pole is\n",
        "        - \"comprehensive\": Considers angle, angular velocity, and cart position\n",
        "        - \"negative_angle\": Penalize based on angle deviation\n",
        "        \"\"\"\n",
        "        super().__init__(env)\n",
        "        self.reward_type = reward_type\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return self.env.reset(**kwargs)\n",
        "\n",
        "    def step(self, action):\n",
        "        state, reward, terminated, truncated, info = self.env.step(action)\n",
        "\n",
        "        # Extract state variables\n",
        "        x, x_dot, theta, theta_dot = state\n",
        "\n",
        "        # Customize reward based on type\n",
        "        if self.reward_type == \"default\":\n",
        "            custom_reward = reward\n",
        "\n",
        "        elif self.reward_type == \"angle_based\":\n",
        "            # Reward is higher when pole is more upright (theta closer to 0)\n",
        "            # Max reward of 1 when perfectly upright, decreases with angle\n",
        "            custom_reward = 1.0 - (abs(theta) / np.deg2rad(90))\n",
        "\n",
        "        elif self.reward_type == \"comprehensive\":\n",
        "            # Combination of multiple factors (balanced for learning)\n",
        "            angle_reward = 1.0 - (abs(theta) / np.deg2rad(90))  # Upright bonus\n",
        "            velocity_penalty = -0.01 * abs(theta_dot)  # Small penalty for angular velocity\n",
        "            position_penalty = -0.01 * abs(x)  # Small penalty for position\n",
        "            # Keep rewards positive and scaled appropriately\n",
        "            custom_reward = max(0, angle_reward + velocity_penalty + position_penalty)\n",
        "\n",
        "        elif self.reward_type == \"negative_angle\":\n",
        "            # Penalize angle deviation (negative reward when tilted)\n",
        "            custom_reward = -abs(theta)\n",
        "        elif self.reward_type == \"custom\":\n",
        "            # User-defined custom reward function\n",
        "            # Example: Reward based on squared angle and position\n",
        "            # angle_component = max(0, 1.0 - (abs(theta) / np.deg2rad(90))**2)\n",
        "            # position_component = max(0, 1.0 - (abs(x) / self.env.unwrapped.x_threshold)**2)\n",
        "            # custom_reward = angle_component + position_component\n",
        "            NotImplementedError(\"Custom reward function not implemented.\")\n",
        "                #=============================================================================================================\n",
        "                #\n",
        "                # You can define your own custom reward function logic here. Change the reward type to \"custom\" in the\n",
        "                # hyperparameters section to use it.\n",
        "                #=============================================================================================================\n",
        "        elif self.reward_type == \"custom_15_deg\":\n",
        "            # Custom reward function that gives a bonus for keeping the pole within 15 degrees\n",
        "            # and keeping the cart centered\n",
        "            \n",
        "            # Target: 15 degrees (convert to radians)\n",
        "            target_angle = np.deg2rad(15)\n",
        "            angle_degrees = abs(np.rad2deg(theta))\n",
        "            \n",
        "            # Angle reward: exponential falloff from target angle\n",
        "            # Peak reward when at exactly 15 degrees\n",
        "            angle_error = abs(abs(theta) - target_angle)\n",
        "            angle_reward = np.exp(-10 * angle_error**2)  # Sharp peak at 15 degrees\n",
        "            \n",
        "            # Stability reward: penalize angular velocity (want to hold steady)\n",
        "            stability_reward = np.exp(-5 * theta_dot**2)\n",
        "            \n",
        "            # Position reward: keep cart centered\n",
        "            # Exponential falloff from center position\n",
        "            position_reward = np.exp(-2 * x**2)\n",
        "            \n",
        "            # Cart velocity penalty: discourage excessive movement\n",
        "            velocity_penalty = np.exp(-0.5 * x_dot**2)\n",
        "            \n",
        "            # Combine all components with weights\n",
        "            # Prioritize angle (most important), then position, then stability\n",
        "            custom_reward = (\n",
        "                2.0 * angle_reward +       # Weight: 2.0 - most important\n",
        "                1.0 * position_reward +     # Weight: 1.0 - keep centered\n",
        "                0.5 * stability_reward +    # Weight: 0.5 - reduce oscillation\n",
        "                0.3 * velocity_penalty      # Weight: 0.3 - smooth movement\n",
        "            )\n",
        "            # dist_error_normalized = x / self.env.unwrapped.x_threshold\n",
        "            # angle_error_normalized = angle_error / np.deg2rad(FAILURE_ANGLE_DEGREES)\n",
        "            state[2] = target_angle-theta # for the PID controller\n",
        "            # Normalize to reasonable range (0 to ~4)\n",
        "            \n",
        "            # This helps the GA distinguish between good and bad solutions\n",
        "            \n",
        "        else:\n",
        "            custom_reward = reward\n",
        "\n",
        "        return state, custom_reward, terminated, truncated, info\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230c4710",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "230c4710",
        "outputId": "463255e8-9f6c-4ba7-ef78-932c7dcbeeaa"
      },
      "outputs": [],
      "source": [
        "# Create the environment with configuration from hyperparameters\n",
        "base_env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "env = LargeAngleCartPole(base_env, theta_threshold_radians=np.deg2rad(FAILURE_ANGLE_DEGREES))\n",
        "env = ContinuousForceCartPole(env, force_mag=FORCE_MAGNITUDE)\n",
        "env = CustomRewardCartPole(env, reward_type=REWARD_TYPE)\n",
        "env.reset(seed=123, options={\"low\": -0.1, \"high\": 0.1})\n",
        "\n",
        "print(f\"Environment created:\")\n",
        "print(f\"  Failure angle: {np.rad2deg(env.env.env.env.unwrapped.theta_threshold_radians):.1f}°\")\n",
        "print(f\"  Action space: Continuous force from {env.action_space.low[0]:.1f} to {env.action_space.high[0]:.1f}\")\n",
        "print(f\"  Reward function: {env.reward_type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95804fe0",
      "metadata": {
        "id": "95804fe0"
      },
      "source": [
        "## PID Controller - The Actual Control Part\n",
        "\n",
        "The `PIDController` class is what actually controls the cart. It's a classic control algorithm from the 1920s that's still used everywhere today because it works and it's simple.\n",
        "\n",
        "### What's Inside\n",
        "\n",
        "**State variables it tracks:**\n",
        "- `integral`: Running sum of all past errors (accumulated error over time)\n",
        "- `prev_error`: What the error was last timestep (needed to calculate rate of change)\n",
        "- `integral_limit`: Cap on how big the integral can get (anti-windup protection)\n",
        "\n",
        "**The control equation:**\n",
        "```\n",
        "force = Kp × error + Ki × ∫error·dt + Kd × (derivative of error)\n",
        "```\n",
        "\n",
        "Breaking it down:\n",
        "- **Kp (Proportional):** Push harder when the pole is tilted more. Simple.\n",
        "- **Ki (Integral):** If there's a constant drift, this fixes it over time. Prevents steady-state error.\n",
        "- **Kd (Derivative):** If the pole is falling fast, this adds damping. Prevents overshooting.\n",
        "\n",
        "The problem? Picking good values for Kp, Ki, and Kd. That's where the genetic algorithm comes in.\n",
        "\n",
        "---\n",
        "\n",
        "### How It Actually Works\n",
        "\n",
        "1. **You give it an error signal:** How far the pole is from vertical (the angle)\n",
        "2. **Proportional term (Kp):** Pushes proportionally to current error\n",
        "   - Pole tilted 10°? Push harder than if it's tilted 2°\n",
        "   - Simple, reactive, but can overshoot\n",
        "3. **Integral term (Ki):** Fixes persistent bias/drift\n",
        "   - If there's a constant error that Kp isn't eliminating, Ki accumulates it and corrects\n",
        "   - **Anti-windup protection:** We clamp this at ±`INTEGRAL_LIMIT` so it doesn't grow forever\n",
        "   - Without this limit, the integral can wind up to huge values and cause instability\n",
        "4. **Derivative term (Kd):** Predicts where things are going\n",
        "   - If the pole is falling fast, apply more damping\n",
        "   - Prevents overshooting and oscillation\n",
        "   - Anticipatory control\n",
        "5. **Output:** Sum of all three terms = force to apply to cart\n",
        "\n",
        "### The Methods\n",
        "\n",
        "- `reset()`: Call this at the start of each episode. Clears integral and previous error.\n",
        "- `compute(error, dt)`: Feed it the current error, get back a force value\n",
        "  - Uses `PID_TIMESTEP` from config (0.02 seconds by default)\n",
        "  - Returns the force command\n",
        "\n",
        "### Why PID for This?\n",
        "\n",
        "- Only 3 parameters to tune (Kp, Ki, Kd) - that's what the GA is for\n",
        "- Doesn't need a model of the physics - just reacts to what it sees\n",
        "- Fast - just some multiplication and addition\n",
        "- Proven - used in cruise control, thermostats, industrial robots, drones, basically everything\n",
        "\n",
        "The GA's job is finding good values for Kp, Ki, and Kd. Manual tuning would take forever and probably wouldn't find the optimal values anyway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead48821",
      "metadata": {
        "id": "ead48821"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from IPython.display import clear_output, display\n",
        "import matplotlib.pyplot as plt # Ensure matplotlib is imported for plotting\n",
        "\n",
        "\n",
        "# PID Controller class\n",
        "class PIDController:\n",
        "    def __init__(self, kp, ki, kd):\n",
        "        self.kp = kp  # Proportional gain\n",
        "        self.ki = ki  # Integral gain\n",
        "        self.kd = kd  # Derivative gain\n",
        "        self.integral = 0\n",
        "        self.prev_error = 0\n",
        "        self.integral_limit = INTEGRAL_LIMIT  # Use hyperparameter\n",
        "\n",
        "    def reset(self):\n",
        "        self.integral = 0\n",
        "        self.prev_error = 0\n",
        "\n",
        "    def compute(self, error, dt=None):\n",
        "        if dt is None:\n",
        "            dt = PID_TIMESTEP  # Use hyperparameter\n",
        "\n",
        "        self.integral += error * dt\n",
        "        # Anti-windup: clamp integral term\n",
        "        self.integral = np.clip(self.integral, -self.integral_limit, self.integral_limit)\n",
        "\n",
        "        derivative = (error - self.prev_error) / dt\n",
        "        output = self.kp * error + self.ki * self.integral + self.kd * derivative\n",
        "\n",
        "        self.prev_error = error\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "# Global variables to hold figure, axes, and image plot for continuous updates\n",
        "_global_fig = None\n",
        "_global_axs = None\n",
        "_global_display_handle = None\n",
        "_global_img_plot = None\n",
        "\n",
        "def _init_plot_for_eval():\n",
        "    \"\"\"Initializes the matplotlib figure and axes for live rendering, only once.\"\"\"\n",
        "    global _global_fig, _global_axs, _global_display_handle, _global_img_plot\n",
        "    if _global_fig is None:\n",
        "        # Create figure and a GridSpec for layout\n",
        "        _global_fig = plt.figure(figsize=(18, 6), constrained_layout=True)\n",
        "        gs = _global_fig.add_gridspec(2, 3) # 2 rows, 3 columns\n",
        "\n",
        "        # Define subplots based on the grid\n",
        "        ax_cart = _global_fig.add_subplot(gs[:, 0]) # CartPole visualization (takes all rows in first column)\n",
        "        ax_fitness = _global_fig.add_subplot(gs[0, 1:]) # Fitness plot (takes top row, second and third columns)\n",
        "        ax_pop = _global_fig.add_subplot(gs[1, 1:]) # Population plot (takes bottom row, second and third columns)\n",
        "\n",
        "        _global_axs = {'cart': ax_cart, 'fitness': ax_fitness, 'pop': ax_pop}\n",
        "\n",
        "        # Get a display handle for updating the figure without clearing output\n",
        "        _global_display_handle = display(_global_fig, display_id=True)\n",
        "        plt.close(_global_fig) # Prevent initial display of empty figure below the handle\n",
        "        _global_img_plot = None # Initialize img_plot as None\n",
        "    return _global_fig, _global_axs, _global_display_handle\n",
        "\n",
        "# Evaluate a PID controller on CartPole\n",
        "def evaluate_pid(kp, ki, kd, episodes=None, max_steps=None, render=False,\n",
        "                 ga_instance=None, current_gen=None, current_individual=None):\n",
        "    if episodes is None:\n",
        "        episodes = EPISODES_PER_EVAL\n",
        "    if max_steps is None:\n",
        "        max_steps = MAX_STEPS_PER_EPISODE\n",
        "\n",
        "    if render:\n",
        "        fig, axs, display_handle = _init_plot_for_eval()\n",
        "        ax_cart = axs['cart']\n",
        "        ax_fitness = axs['fitness']\n",
        "        ax_pop = axs['pop']\n",
        "\n",
        "    total_reward = 0\n",
        "    for episode_idx in range(episodes):\n",
        "        state, _ = env.reset()\n",
        "        pid = PIDController(kp, ki, kd)\n",
        "        episode_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            # Error is the pole angle (state[2])\n",
        "            error = state[2]\n",
        "            # PID output is now directly used as continuous force\n",
        "            force = pid.compute(error)\n",
        "\n",
        "            # Apply the continuous force directly\n",
        "            state, reward, terminated, truncated, _ = env.step(force)\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Render with evolution tracking\n",
        "            if render and ga_instance and step % RENDER_EVERY_N_STEPS == 0:\n",
        "                frame = env.render()\n",
        "\n",
        "                # Clear existing axes content before redrawing\n",
        "                ax_cart.clear()\n",
        "                ax_fitness.clear()\n",
        "                ax_pop.clear()\n",
        "\n",
        "                # CartPole visualization\n",
        "                global _global_img_plot # Access the global image plot handle\n",
        "                if _global_img_plot is None or _global_img_plot.axes != ax_cart:\n",
        "                    _global_img_plot = ax_cart.imshow(frame)\n",
        "                else:\n",
        "                    _global_img_plot.set_data(frame)\n",
        "                ax_cart.axis('off')\n",
        "                ax_cart.set_title(f'Gen {current_gen}/{ga_instance.generations} | Individual {current_individual}/{ga_instance.population_size}\\n' +\n",
        "                                 f'P: {kp:.2f} I: {ki:.2f} D: {kd:.2f} | Step: {step}/{max_steps}\\n' +\n",
        "                                 f'Reward: {episode_reward:.1f}',\n",
        "                                 fontsize=12, fontweight='bold')\n",
        "\n",
        "                # Top Right: Best and Average Fitness Over Generations\n",
        "                if ga_instance.best_fitness_history:\n",
        "                    generations_hist = range(1, len(ga_instance.best_fitness_history) + 1)\n",
        "                    ax_fitness.plot(generations_hist, ga_instance.best_fitness_history,\n",
        "                                   'g-o', linewidth=2, markersize=6, label='Best Fitness')\n",
        "                    ax_fitness.plot(generations_hist, ga_instance.avg_fitness_history,\n",
        "                                   'b-s', linewidth=2, markersize=4, alpha=0.7, label='Avg Fitness')\n",
        "                    ax_fitness.axvline(x=current_gen, color='red', linestyle='--',\n",
        "                                      linewidth=2, label='Current Gen', alpha=0.7)\n",
        "                    ax_fitness.set_xlabel('Generation', fontsize=11)\n",
        "                    ax_fitness.set_ylabel('Fitness', fontsize=11)\n",
        "                    ax_fitness.set_title('Evolution Progress', fontsize=12, fontweight='bold')\n",
        "                    ax_fitness.legend(loc='best')\n",
        "                    ax_fitness.grid(True, alpha=0.3)\n",
        "                else:\n",
        "                    ax_fitness.text(0.5, 0.5, 'Waiting for generation data...',\n",
        "                                   ha='center', va='center', fontsize=12, transform=ax_fitness.transAxes)\n",
        "                    ax_fitness.set_xlim(0, 1)\n",
        "                    ax_fitness.set_ylim(0, 1)\n",
        "\n",
        "                # Bottom Right: Current Generation Population Performance\n",
        "                if ga_instance.current_generation_fitness is not None:\n",
        "                    individuals_pop = range(1, len(ga_instance.current_generation_fitness) + 1)\n",
        "                    colors = ['red' if i == current_individual else 'skyblue'\n",
        "                             for i in individuals_pop]\n",
        "                    bars = ax_pop.bar(individuals_pop, ga_instance.current_generation_fitness,\n",
        "                                     color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "                    # Highlight current individual\n",
        "                    if current_individual is not None and current_individual <= len(bars):\n",
        "                        bars[current_individual-1].set_linewidth(3)\n",
        "                        bars[current_individual-1].set_edgecolor('darkred')\n",
        "\n",
        "                    ax_pop.axhline(y=np.mean(ga_instance.current_generation_fitness),\n",
        "                                  color='blue', linestyle='--', linewidth=2,\n",
        "                                  label=f'Gen Avg: {np.mean(ga_instance.current_generation_fitness):.1f}', alpha=0.7)\n",
        "                    ax_pop.axhline(y=np.max(ga_instance.current_generation_fitness),\n",
        "                                  color='green', linestyle='--', linewidth=2,\n",
        "                                  label=f'Gen Best: {np.max(ga_instance.current_generation_fitness):.1f}', alpha=0.7)\n",
        "\n",
        "                    ax_pop.set_xlabel('Individual', fontsize=11)\n",
        "                    ax_pop.set_ylabel('Fitness', fontsize=11)\n",
        "                    ax_pop.set_title(f'Generation {current_gen} Population Performance',\n",
        "                                    fontsize=12, fontweight='bold')\n",
        "                    ax_pop.legend(loc='best')\n",
        "                    ax_pop.grid(True, alpha=0.3, axis='y')\n",
        "                else:\n",
        "                    ax_pop.text(0.5, 0.5, 'Evaluating population...',\n",
        "                               ha='center', va='center', fontsize=12, transform=ax_pop.transAxes)\n",
        "                    ax_pop.set_xlim(0, 1)\n",
        "                    ax_pop.set_ylim(0, 1)\n",
        "\n",
        "                # Update the displayed figure\n",
        "                display_handle.update(fig)\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        total_reward += episode_reward\n",
        "\n",
        "    return total_reward / episodes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "182ce483",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generation 14/40\n",
            "Best Fitness: 233.31, Avg Fitness: 179.35\n",
            "Best Angle PID: Kp=-6.216, Ki=-3.485, Kd=-13.626\n",
            "Best Pos PID:   Kp=0.642, Ki=-0.674, Kd=-1.537\n",
            "------------------------------------------------------------\n",
            "\n",
            "Generation 15/40\n",
            "Best Fitness: 232.06, Avg Fitness: 188.85\n",
            "Best Angle PID: Kp=-6.539, Ki=-2.884, Kd=-10.978\n",
            "Best Pos PID:   Kp=0.827, Ki=-0.634, Kd=-0.968\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cascaded PID Controller - simple version\n",
        "class CascadedPIDController:\n",
        "    \"\"\"\n",
        "    Two PIDs in series:\n",
        "    - Outer loop: controls position (slow)\n",
        "    - Inner loop: controls angle (fast)\n",
        "    \"\"\"\n",
        "    def __init__(self, kp_angle, ki_angle, kd_angle, kp_pos, ki_pos, kd_pos, target_angle=0.0):\n",
        "        self.angle_pid = PIDController(kp_angle, ki_angle, kd_angle)\n",
        "        self.position_pid = PIDController(kp_pos, ki_pos, kd_pos)\n",
        "        self.target_angle = target_angle  # Desired angle (e.g., 15 degrees in radians)\n",
        "        \n",
        "    def reset(self):\n",
        "        self.angle_pid.reset()\n",
        "        self.position_pid.reset()\n",
        "    \n",
        "    def compute(self, cart_position, pole_angle, dt=None):\n",
        "        \"\"\"\n",
        "        Cascaded control:\n",
        "        1. Position PID adjusts the target angle to keep cart centered\n",
        "        2. Angle PID tracks the adjusted target angle\n",
        "        \"\"\"\n",
        "        # Outer loop: position error → angle adjustment\n",
        "        # If cart drifts right, we want to tilt left to bring it back\n",
        "        position_error = -cart_position  # Negative because we want to go toward center\n",
        "        angle_adjustment = self.position_pid.compute(position_error, dt)\n",
        "        \n",
        "        # Inner loop: angle error → force\n",
        "        adjusted_target = self.target_angle + angle_adjustment\n",
        "        angle_error = adjusted_target - pole_angle\n",
        "        force = self.angle_pid.compute(angle_error, dt)\n",
        "        \n",
        "        return force\n",
        "\n",
        "\n",
        "# Evaluation function for cascaded controller\n",
        "def evaluate_cascaded_pid(angle_gains, position_gains, target_angle=0.0, \n",
        "                          episodes=None, max_steps=None, render=False,\n",
        "                          ga_instance=None, current_gen=None, current_individual=None):\n",
        "    \"\"\"\n",
        "    Evaluate cascaded PID controller.\n",
        "    angle_gains: [kp, ki, kd] for angle control\n",
        "    position_gains: [kp, ki, kd] for position control\n",
        "    \"\"\"\n",
        "    if episodes is None:\n",
        "        episodes = EPISODES_PER_EVAL\n",
        "    if max_steps is None:\n",
        "        max_steps = MAX_STEPS_PER_EPISODE\n",
        "\n",
        "    if render:\n",
        "        fig, axs, display_handle = _init_plot_for_eval()\n",
        "        ax_cart = axs['cart']\n",
        "        ax_fitness = axs['fitness']\n",
        "        ax_pop = axs['pop']\n",
        "\n",
        "    total_reward = 0\n",
        "    for episode_idx in range(episodes):\n",
        "        state, _ = env.reset()\n",
        "        controller = CascadedPIDController(\n",
        "            angle_gains[0], angle_gains[1], angle_gains[2],\n",
        "            position_gains[0], position_gains[1], position_gains[2],\n",
        "            target_angle=target_angle\n",
        "        )\n",
        "        episode_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            x, x_dot, theta, theta_dot = state\n",
        "            \n",
        "            # Cascaded control computes force from position and angle\n",
        "            force = controller.compute(x, theta)\n",
        "\n",
        "            # Apply the force\n",
        "            state, reward, terminated, truncated, _ = env.step(force)\n",
        "            episode_reward += reward\n",
        "\n",
        "            # Render with evolution tracking (same as before)\n",
        "            if render and ga_instance and step % RENDER_EVERY_N_STEPS == 0:\n",
        "                frame = env.render()\n",
        "                ax_cart.clear()\n",
        "                ax_fitness.clear()\n",
        "                ax_pop.clear()\n",
        "\n",
        "                global _global_img_plot\n",
        "                if _global_img_plot is None or _global_img_plot.axes != ax_cart:\n",
        "                    _global_img_plot = ax_cart.imshow(frame)\n",
        "                else:\n",
        "                    _global_img_plot.set_data(frame)\n",
        "                ax_cart.axis('off')\n",
        "                ax_cart.set_title(f'Gen {current_gen}/{ga_instance.generations} | Individual {current_individual}/{ga_instance.population_size}\\n' +\n",
        "                                 f'Angle PID: {angle_gains[0]:.2f}, {angle_gains[1]:.2f}, {angle_gains[2]:.2f}\\n' +\n",
        "                                 f'Pos PID: {position_gains[0]:.2f}, {position_gains[1]:.2f}, {position_gains[2]:.2f} | Reward: {episode_reward:.1f}',\n",
        "                                 fontsize=10, fontweight='bold')\n",
        "\n",
        "                if ga_instance.best_fitness_history:\n",
        "                    generations_hist = range(1, len(ga_instance.best_fitness_history) + 1)\n",
        "                    ax_fitness.plot(generations_hist, ga_instance.best_fitness_history,\n",
        "                                   'g-o', linewidth=2, markersize=6, label='Best Fitness')\n",
        "                    ax_fitness.plot(generations_hist, ga_instance.avg_fitness_history,\n",
        "                                   'b-s', linewidth=2, markersize=4, alpha=0.7, label='Avg Fitness')\n",
        "                    ax_fitness.axvline(x=current_gen, color='red', linestyle='--',\n",
        "                                      linewidth=2, label='Current Gen', alpha=0.7)\n",
        "                    ax_fitness.set_xlabel('Generation', fontsize=11)\n",
        "                    ax_fitness.set_ylabel('Fitness', fontsize=11)\n",
        "                    ax_fitness.set_title('Evolution Progress', fontsize=12, fontweight='bold')\n",
        "                    ax_fitness.legend(loc='best')\n",
        "                    ax_fitness.grid(True, alpha=0.3)\n",
        "\n",
        "                if ga_instance.current_generation_fitness is not None:\n",
        "                    individuals_pop = range(1, len(ga_instance.current_generation_fitness) + 1)\n",
        "                    colors = ['red' if i == current_individual else 'skyblue' for i in individuals_pop]\n",
        "                    bars = ax_pop.bar(individuals_pop, ga_instance.current_generation_fitness,\n",
        "                                     color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "                    if current_individual is not None and current_individual <= len(bars):\n",
        "                        bars[current_individual-1].set_linewidth(3)\n",
        "                        bars[current_individual-1].set_edgecolor('darkred')\n",
        "                    ax_pop.axhline(y=np.mean(ga_instance.current_generation_fitness),\n",
        "                                  color='blue', linestyle='--', linewidth=2,\n",
        "                                  label=f'Gen Avg: {np.mean(ga_instance.current_generation_fitness):.1f}')\n",
        "                    ax_pop.axhline(y=np.max(ga_instance.current_generation_fitness),\n",
        "                                  color='green', linestyle='--', linewidth=2,\n",
        "                                  label=f'Gen Best: {np.max(ga_instance.current_generation_fitness):.1f}')\n",
        "                    ax_pop.set_xlabel('Individual', fontsize=11)\n",
        "                    ax_pop.set_ylabel('Fitness', fontsize=11)\n",
        "                    ax_pop.set_title(f'Generation {current_gen} Population Performance', fontsize=12, fontweight='bold')\n",
        "                    ax_pop.legend(loc='best')\n",
        "                    ax_pop.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "                display_handle.update(fig)\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        total_reward += episode_reward\n",
        "\n",
        "    return total_reward / episodes\n",
        "# Cascaded Genetic Algorithm - evolves 6 parameters (both PIDs)\n",
        "class CascadedGeneticAlgorithm:\n",
        "    \"\"\"\n",
        "    Genetic algorithm for cascaded PID controller.\n",
        "    Evolves 6 parameters: [Kp_angle, Ki_angle, Kd_angle, Kp_pos, Ki_pos, Kd_pos]\n",
        "    \"\"\"\n",
        "    def __init__(self, population_size=None, generations=None, target_angle=0.0,\n",
        "                 angle_kp_range=None, angle_ki_range=None, angle_kd_range=None,\n",
        "                 pos_kp_range=None, pos_ki_range=None, pos_kd_range=None):\n",
        "        self.population_size = population_size if population_size is not None else POPULATION_SIZE\n",
        "        self.generations = generations if generations is not None else GENERATIONS\n",
        "        self.target_angle = target_angle\n",
        "        \n",
        "        # Default ranges for cascaded system\n",
        "        # Angle PID typically needs larger gains (fast inner loop)\n",
        "        self.angle_kp_range = angle_kp_range if angle_kp_range is not None else (-50, 50)\n",
        "        self.angle_ki_range = angle_ki_range if angle_ki_range is not None else (-20, 20)\n",
        "        self.angle_kd_range = angle_kd_range if angle_kd_range is not None else (-30, 30)\n",
        "        \n",
        "        # Position PID typically needs smaller gains (slow outer loop)\n",
        "        self.pos_kp_range = pos_kp_range if pos_kp_range is not None else (-10, 10)\n",
        "        self.pos_ki_range = pos_ki_range if pos_ki_range is not None else (-5, 5)\n",
        "        self.pos_kd_range = pos_kd_range if pos_kd_range is not None else (-10, 10)\n",
        "        \n",
        "        self.best_fitness_history = []\n",
        "        self.avg_fitness_history = []\n",
        "        self.individual_fitness_history = []\n",
        "        self.current_generation_fitness = None\n",
        "\n",
        "    def initialize_population(self):\n",
        "        \"\"\"Initialize population with 6 parameters per individual\"\"\"\n",
        "        population = []\n",
        "        \n",
        "        ranges = [\n",
        "            self.angle_kp_range, self.angle_ki_range, self.angle_kd_range,\n",
        "            self.pos_kp_range, self.pos_ki_range, self.pos_kd_range\n",
        "        ]\n",
        "        \n",
        "        for _ in range(self.population_size):\n",
        "            individual = []\n",
        "            for r in ranges:\n",
        "                r_size = r[1] - r[0]\n",
        "                # Initialize in middle 30-60% of range\n",
        "                value = r[0] + np.random.uniform(0.3, 0.6) * r_size\n",
        "                individual.append(value)\n",
        "            population.append(individual)\n",
        "        \n",
        "        return np.array(population)\n",
        "\n",
        "    def evaluate_population(self, population, current_gen):\n",
        "        \"\"\"Evaluate each individual (6 parameters) on cascaded controller\"\"\"\n",
        "        fitness = []\n",
        "        for idx, ind in enumerate(population):\n",
        "            render = VISUALIZE_ALL_INDIVIDUALS_DURING_TRAINING\n",
        "            \n",
        "            # Split 6 parameters into angle_gains and position_gains\n",
        "            angle_gains = ind[:3]\n",
        "            position_gains = ind[3:]\n",
        "            \n",
        "            fit = evaluate_cascaded_pid(\n",
        "                angle_gains, position_gains, \n",
        "                target_angle=self.target_angle,\n",
        "                render=render,\n",
        "                ga_instance=self, \n",
        "                current_gen=current_gen,\n",
        "                current_individual=idx+1\n",
        "            )\n",
        "            fitness.append(fit)\n",
        "            \n",
        "            self.current_generation_fitness = np.array(fitness + [0] * (self.population_size - len(fitness)))\n",
        "        \n",
        "        # Render best individual if not visualizing all\n",
        "        best_idx = np.argmax(fitness)\n",
        "        if not VISUALIZE_ALL_INDIVIDUALS_DURING_TRAINING:\n",
        "            angle_gains = population[best_idx][:3]\n",
        "            position_gains = population[best_idx][3:]\n",
        "            evaluate_cascaded_pid(\n",
        "                angle_gains, position_gains,\n",
        "                target_angle=self.target_angle,\n",
        "                render=True,\n",
        "                ga_instance=self,\n",
        "                current_gen=current_gen,\n",
        "                current_individual=best_idx+1,\n",
        "                episodes=1\n",
        "            )\n",
        "        \n",
        "        return np.array(fitness)\n",
        "\n",
        "    def selection(self, population, fitness):\n",
        "        \"\"\"Tournament selection\"\"\"\n",
        "        selected = []\n",
        "        for _ in range(self.population_size):\n",
        "            i, j = np.random.choice(self.population_size, 2, replace=False)\n",
        "            selected.append(population[i] if fitness[i] > fitness[j] else population[j])\n",
        "        return np.array(selected)\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        \"\"\"Single-point crossover for 6 parameters\"\"\"\n",
        "        if np.random.rand() < CROSSOVER_RATE:\n",
        "            point = np.random.randint(1, 6)\n",
        "            child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
        "            child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
        "            return child1, child2\n",
        "        return parent1.copy(), parent2.copy()\n",
        "\n",
        "    def mutate(self, individual):\n",
        "        \"\"\"Gaussian mutation for 6 parameters\"\"\"\n",
        "        ranges = [\n",
        "            self.angle_kp_range, self.angle_ki_range, self.angle_kd_range,\n",
        "            self.pos_kp_range, self.pos_ki_range, self.pos_kd_range\n",
        "        ]\n",
        "        \n",
        "        for i in range(len(individual)):\n",
        "            if np.random.rand() < MUTATION_RATE:\n",
        "                individual[i] += np.random.normal(0, abs(individual[i]) * MUTATION_EFFECT)\n",
        "                individual[i] = np.clip(individual[i], ranges[i][0], ranges[i][1])\n",
        "        \n",
        "        return individual\n",
        "\n",
        "    def evolve(self):\n",
        "        \"\"\"Main evolution loop\"\"\"\n",
        "        population = self.initialize_population()\n",
        "        \n",
        "        for gen in range(1, self.generations + 1):\n",
        "            fitness = self.evaluate_population(population, gen)\n",
        "            \n",
        "            best_idx = np.argmax(fitness)\n",
        "            best_fitness = fitness[best_idx]\n",
        "            avg_fitness = np.mean(fitness)\n",
        "            \n",
        "            self.best_fitness_history.append(best_fitness)\n",
        "            self.avg_fitness_history.append(avg_fitness)\n",
        "            self.individual_fitness_history.append(fitness)\n",
        "            \n",
        "            best_ind = population[best_idx]\n",
        "            print(f\"\\nGeneration {gen}/{self.generations}\")\n",
        "            print(f\"Best Fitness: {best_fitness:.2f}, Avg Fitness: {avg_fitness:.2f}\")\n",
        "            print(f\"Best Angle PID: Kp={best_ind[0]:.3f}, Ki={best_ind[1]:.3f}, Kd={best_ind[2]:.3f}\")\n",
        "            print(f\"Best Pos PID:   Kp={best_ind[3]:.3f}, Ki={best_ind[4]:.3f}, Kd={best_ind[5]:.3f}\")\n",
        "            print(\"-\" * 60)\n",
        "            \n",
        "            # Early stopping if converged\n",
        "            if best_fitness - avg_fitness < 5:\n",
        "                print(f\"Converged at generation {gen}\")\n",
        "                break\n",
        "            \n",
        "            # Selection\n",
        "            selected = self.selection(population, fitness)\n",
        "            \n",
        "            # Crossover and Mutation\n",
        "            new_population = []\n",
        "            if ELITISM:\n",
        "                new_population.append(population[best_idx])\n",
        "            \n",
        "            for i in range(0, self.population_size - len(new_population), 2):\n",
        "                parent1 = selected[i]\n",
        "                parent2 = selected[i+1] if i+1 < self.population_size else selected[0]\n",
        "                child1, child2 = self.crossover(parent1, parent2)\n",
        "                child1 = self.mutate(child1)\n",
        "                child2 = self.mutate(child2)\n",
        "                new_population.extend([child1, child2])\n",
        "            \n",
        "            population = np.array(new_population[:self.population_size])\n",
        "        \n",
        "        # Final evaluation\n",
        "        fitness = self.evaluate_population(population, self.generations)\n",
        "        best_idx = np.argmax(fitness)\n",
        "        return population[best_idx], fitness[best_idx]\n",
        "# Train Cascaded PID Controller with GA\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CASCADED PID GENETIC ALGORITHM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Set target angle (15 degrees in radians)\n",
        "TARGET_ANGLE_DEG = 15\n",
        "target_angle_rad = np.deg2rad(TARGET_ANGLE_DEG)\n",
        "\n",
        "# Create cascaded GA instance\n",
        "cascaded_ga = CascadedGeneticAlgorithm(\n",
        "    population_size=20,\n",
        "    generations=40,\n",
        "    target_angle=target_angle_rad,\n",
        "    # Angle PID ranges (inner loop - larger gains)\n",
        "    angle_kp_range=(-50, 50),\n",
        "    angle_ki_range=(-20, 20),\n",
        "    angle_kd_range=(-30, 30),\n",
        "    # Position PID ranges (outer loop - smaller gains)\n",
        "    pos_kp_range=(-10, 10),\n",
        "    pos_ki_range=(-5, 5),\n",
        "    pos_kd_range=(-10, 10)\n",
        ")\n",
        "\n",
        "print(f\"\\nTarget angle: {TARGET_ANGLE_DEG}°\")\n",
        "print(f\"Population: {cascaded_ga.population_size}\")\n",
        "print(f\"Generations: {cascaded_ga.generations}\")\n",
        "print(f\"\\nAngle PID ranges: Kp{cascaded_ga.angle_kp_range}, Ki{cascaded_ga.angle_ki_range}, Kd{cascaded_ga.angle_kd_range}\")\n",
        "print(f\"Position PID ranges: Kp{cascaded_ga.pos_kp_range}, Ki{cascaded_ga.pos_ki_range}, Kd{cascaded_ga.pos_kd_range}\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Run evolution\n",
        "best_params, best_fitness = cascaded_ga.evolve()\n",
        "\n",
        "# Extract angle and position PID parameters\n",
        "best_angle_pid = best_params[:3]\n",
        "best_pos_pid = best_params[3:]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CASCADED PID RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Target Angle: {TARGET_ANGLE_DEG}°\")\n",
        "print(f\"\\nBest Angle PID (Inner Loop):\")\n",
        "print(f\"  Kp={best_angle_pid[0]:.3f}, Ki={best_angle_pid[1]:.3f}, Kd={best_angle_pid[2]:.3f}\")\n",
        "print(f\"\\nBest Position PID (Outer Loop):\")\n",
        "print(f\"  Kp={best_pos_pid[0]:.3f}, Ki={best_pos_pid[1]:.3f}, Kd={best_pos_pid[2]:.3f}\")\n",
        "print(f\"\\nBest Fitness: {best_fitness:.2f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Plot evolution\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(cascaded_ga.best_fitness_history, 'g-o', linewidth=2, markersize=8, label='Best Fitness')\n",
        "plt.plot(cascaded_ga.avg_fitness_history, 'b-s', linewidth=2, markersize=6, label='Average Fitness')\n",
        "plt.xlabel('Generation', fontsize=12)\n",
        "plt.ylabel('Fitness', fontsize=12)\n",
        "plt.title(f'Cascaded PID Evolution (Target: {TARGET_ANGLE_DEG}°)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "improvement = np.array(cascaded_ga.best_fitness_history) - cascaded_ga.best_fitness_history[0]\n",
        "plt.bar(range(1, len(improvement)+1), improvement, color='purple', alpha=0.6, edgecolor='black')\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "plt.xlabel('Generation', fontsize=12)\n",
        "plt.ylabel('Improvement from Gen 1', fontsize=12)\n",
        "plt.title('Fitness Improvement', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# Demonstrate best cascaded controller\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DEMONSTRATING BEST CASCADED CONTROLLER\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Target: {TARGET_ANGLE_DEG}° pole angle\")\n",
        "print(f\"Angle PID: Kp={best_angle_pid[0]:.3f}, Ki={best_angle_pid[1]:.3f}, Kd={best_angle_pid[2]:.3f}\")\n",
        "print(f\"Pos PID:   Kp={best_pos_pid[0]:.3f}, Ki={best_pos_pid[1]:.3f}, Kd={best_pos_pid[2]:.3f}\")\n",
        "print(\"\\nWatch the CartPole hold the angled position:\")\n",
        "\n",
        "# Run extended demo\n",
        "demo_score = evaluate_cascaded_pid(\n",
        "    best_angle_pid, \n",
        "    best_pos_pid,\n",
        "    target_angle=target_angle_rad,\n",
        "    episodes=1,\n",
        "    max_steps=500,\n",
        "    render=True,\n",
        "    ga_instance=cascaded_ga,\n",
        "    current_gen=cascaded_ga.generations,\n",
        "    current_individual=1\n",
        ")\n",
        "\n",
        "print(f\"\\nDemo score: {demo_score:.2f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e6f3d6",
      "metadata": {},
      "source": [
        "## Cascaded PID Training with Genetic Algorithm\n",
        "\n",
        "This section evolves BOTH PIDs simultaneously (6 parameters total) for the cascaded controller.\n",
        "\n",
        "**What's different from single PID:**\n",
        "- Evolves 6 parameters instead of 3\n",
        "- Angle PID (inner loop): Fast response, larger gains\n",
        "- Position PID (outer loop): Slow response, smaller gains\n",
        "- Target angle can be set (e.g., 15 degrees)\n",
        "\n",
        "**When to use this:**\n",
        "- When single PID causes cart drift\n",
        "- When holding non-vertical angles (like 15°)\n",
        "- When you need both angle AND position control\n",
        "\n",
        "**Parameter relationships:**\n",
        "- Angle PID gains typically 5-10x larger than position PID\n",
        "- Position PID adjusts target angle based on cart position\n",
        "- Angle PID tracks the adjusted target\n",
        "\n",
        "Run the cell below to train the cascaded controller."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f214327",
      "metadata": {},
      "source": [
        "## Manual Testing of Cascaded Controller\n",
        "\n",
        "If you want to test specific gain values without running the full GA, use this cell:\n",
        "\n",
        "```python\n",
        "# Example: Test manually chosen gains\n",
        "test_angle_gains = [20.0, 0.5, 10.0]  # [Kp, Ki, Kd] for angle\n",
        "test_pos_gains = [2.0, 0.1, 1.0]      # [Kp, Ki, Kd] for position\n",
        "test_target = np.deg2rad(15)          # 15 degree target\n",
        "\n",
        "score = evaluate_cascaded_pid(\n",
        "    test_angle_gains, \n",
        "    test_pos_gains,\n",
        "    target_angle=test_target,\n",
        "    episodes=3,\n",
        "    render=True\n",
        ")\n",
        "print(f\"Manual test score: {score:.2f}\")\n",
        "```\n",
        "\n",
        "**Tuning tips:**\n",
        "- Angle PID should be 5-10x larger than position PID\n",
        "- Start with angle PID, get it working for vertical (0°)\n",
        "- Then add small position PID gains\n",
        "- Increase position gains gradually until cart stays centered\n",
        "- Too much position gain → oscillation\n",
        "- Too little position gain → cart drifts off screen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d574c046",
      "metadata": {
        "id": "d574c046"
      },
      "source": [
        "## 3D Fitness Landscape Visualization\n",
        "\n",
        "This visualization shows the fitness of every individual across all generations. It's a great way to see:\n",
        "- How the population spreads out initially (exploration)\n",
        "- How it converges over time (exploitation)\n",
        "- Which individuals dominated each generation\n",
        "- Whether the population maintained diversity or got stuck\n",
        "\n",
        "**What you're looking at:**\n",
        "- X-axis: Individual number (1 to POPULATION_SIZE)\n",
        "- Y-axis: Generation number\n",
        "- Z-axis (height): Fitness score\n",
        "- Colors: Fitness level (warmer = better)\n",
        "\n",
        "**Patterns to look for:**\n",
        "- **Steady climb:** Heights increase over generations = evolution working\n",
        "- **Plateau:** Flat top = converged (or stuck in local optimum)\n",
        "- **Wide spread:** Bars vary a lot = high diversity (good early, concerning late)\n",
        "- **Narrow peaks:** All bars similar = low diversity (good if fitness is high, bad if it's low)\n",
        "- **Single tall bar with low others:** Elitism keeping the best while exploring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9b526ef",
      "metadata": {
        "id": "d9b526ef"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Create 3D fitness landscape\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Prepare data\n",
        "num_generations = len(ga.individual_fitness_history)\n",
        "num_individuals = ga.population_size\n",
        "\n",
        "# Create meshgrid for bar positions\n",
        "xpos, ypos = np.meshgrid(np.arange(num_individuals), np.arange(num_generations))\n",
        "xpos = xpos.flatten()\n",
        "ypos = ypos.flatten()\n",
        "zpos = np.zeros_like(xpos)\n",
        "\n",
        "# Flatten fitness data for bar heights\n",
        "fitness_data = np.array(ga.individual_fitness_history)\n",
        "dz = fitness_data.flatten()\n",
        "\n",
        "# Bar dimensions\n",
        "dx = dy = 0.8\n",
        "\n",
        "# Color mapping based on fitness (normalize to 0-1 range)\n",
        "colors = plt.cm.viridis((dz - dz.min()) / (dz.max() - dz.min() + 1e-8))\n",
        "\n",
        "# Create 3D bar chart\n",
        "ax.bar3d(xpos, ypos, zpos, dx, dy, dz, color=colors, shade=True, alpha=0.8)\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel('Individual', fontsize=12, labelpad=10)\n",
        "ax.set_ylabel('Generation', fontsize=12, labelpad=10)\n",
        "ax.set_zlabel('Fitness', fontsize=12, labelpad=10)\n",
        "ax.set_title('Population Fitness Evolution: 3D Landscape\\n' +\n",
        "             f'Total Individuals: {num_individuals} | Generations: {num_generations}',\n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Set better viewing angle\n",
        "ax.view_init(elev=25, azim=-45)\n",
        "\n",
        "# Add colorbar\n",
        "mappable = plt.cm.ScalarMappable(cmap='viridis',\n",
        "                                  norm=plt.Normalize(vmin=dz.min(), vmax=dz.max()))\n",
        "mappable.set_array(dz)\n",
        "cbar = plt.colorbar(mappable, ax=ax, shrink=0.6, aspect=10, pad=0.1)\n",
        "cbar.set_label('Fitness Level', rotation=270, labelpad=20, fontsize=11)\n",
        "\n",
        "# Grid for better depth perception\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print some statistics\n",
        "print(\"=\"*70)\n",
        "print(\"3D FITNESS LANDSCAPE STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total evaluations: {num_individuals * num_generations}\")\n",
        "print(f\"Fitness range: {dz.min():.2f} to {dz.max():.2f}\")\n",
        "print(f\"Overall improvement: {dz.max() - fitness_data[0].mean():.2f} ({((dz.max() - fitness_data[0].mean()) / fitness_data[0].mean() * 100):.1f}%)\")\n",
        "print(f\"\\nFirst generation - Mean: {fitness_data[0].mean():.2f}, Std: {fitness_data[0].std():.2f}\")\n",
        "print(f\"Last generation  - Mean: {fitness_data[-1].mean():.2f}, Std: {fitness_data[-1].std():.2f}\")\n",
        "print(f\"\\nDiversity trend: {'Converging' if fitness_data[-1].std() < fitness_data[0].std() else 'Maintaining diversity'}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0478140f",
      "metadata": {
        "id": "0478140f"
      },
      "outputs": [],
      "source": [
        "# Demonstrate the best controller with visualization\n",
        "print(\"Demonstrating the best PID controller...\")\n",
        "print(f\"Using: Kp={best_pid[0]:.3f}, Ki={best_pid[1]:.3f}, Kd={best_pid[2]:.3f}\")\n",
        "print(\"\\nWatch the CartPole balance below:\")\n",
        "\n",
        "# Run one episode with rendering\n",
        "final_score = evaluate_pid(best_pid[0], best_pid[1], best_pid[2], render=True,\n",
        "                             ga_instance=ga, current_gen=0,\n",
        "                             current_individual=0)\n",
        "print(f\"\\nFinal score: {final_score:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
